我认为大模型提效的核心是如何高效的喂上下文。大模型不理解你说的话。 它就是根据你给的上下文，预测概率最高的下一个词。所以你喂的信息越精准，它输出的东西就越能用。
低上下文场景：
比如：要写一个列表页的 WXML 骨架、一堆表单校验逻辑、或者把后端返回的数据做一层格式化。
直接描述清楚输入输出，让 AI 秒出，过一眼确认没问题就行。
高上下文场景：
比如：要做一个小程序的用户授权登录模块。
你跟 AI 说"帮我写个登录模块"——它大概率给你一个最基础的 wx.login demo，跟你项目里已有的请求封装、状态管理、token 刷新机制完全对不上。
因为它不知道你项目长什么样。 AI 是概率预测，它没有你的上下文，就只能输出训练语料里最"标准"的方案。
正确的做法是给锚点：
第一步：定义角色与投喂上下文。
"你是一个资深小程序开发工程师，我项目里请求封装在 utils/request.js，token 存 storage 里由 auth.js 统一管理，现在要在这套机制下接入微信登录，code 换 session_key 走 /api/login 接口。" 
第二步：让大模型出方案与质疑。
#这里需要补充内容。
第三步：切片执行与测试。
#这里需要补充内容。
#测试阶段需要填充数据或者接口时，可以通过ai生成python脚本，辅助测试。






Research → Plan → Implementation 的三阶段框架
1. 手动分割上下文，极致利用有效窗口
Claude Code 的有效上下文大约 80K，超了就会"变笨"。不要在一个对话里既让它分析需求、又让它写代码、又让它帮你调 Bug。每个阶段单开一轮对话，把上一轮的结论存下来带到下一轮，效果远好于一个长对话糊到底。
2. 多模型协作：不同模型干不同的活
Gemini擅长前端/UI，Codex擅长后端/逻辑。不一定要只用一个模型。写样式找擅长视觉的模型，写逻辑找擅长推理的模型，你自己做最终审查。
3. 用"约束集"代替"需求描述"
跟 AI 说需求的时候，除了说"我要什么"，更要说"我不要什么"。比如"不要用第三方 UI 库"、"不要新建路由"、"数据格式跟这个接口一致"——约束越明确，AI 越不会乱跑。
4. 零决策流水线
Plan 阶段的退出条件是：所有模糊点都被消除，实现阶段可以零决策顺序执行。 这意味着到了写代码的时候，AI 不需要"想"，只需要"照着做"。
