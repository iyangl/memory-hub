大模型提效的核心：怎么喂上下文
大模型不理解你说的话，它就是根据你给的上下文预测概率最高的下一个词。你喂的信息越精准，它输出的东西就越能用。 搞不清楚这点，用什么工具都一样。

我把平时写小程序的用法分两类来说。

低上下文场景：想清楚了就别自己写
列表页骨架、表单校验、数据格式化、调个样式动画——这些你脑子里已经很清楚要什么的活，直接描述输入输出让 AI 出，过一眼就行。没什么技巧，体力活全部外包。

高上下文场景：三步走
这才是拉开差距的地方。

比如你要做小程序的登录模块，你说"帮我写个登录"——它大概率给你一个标准 wx.login demo，跟你项目里已有的请求封装、状态管理完全对不上。因为它没你的上下文，只能猜最"通用"的写法。

第一步：喂上下文，定边界
先把项目关键信息给到位："请求封装在 utils/request.js，token 由 auth.js 管理，code 换 session 走 /api/login。"

然后说清楚"不要什么"——不要引第三方 SDK、不要新建全局状态、token 刷新复用现有逻辑。约束越明确，AI 越不乱跑。

如果你长期维护一个项目，这些信息可以提前写成一份项目说明文件，AI 每次启动自动加载，不用每次重讲一遍。

第二步：让它出方案，然后质疑
拿到方案别直接用。追问它：并发刷新 token 会不会重复请求？用户拒绝授权后降级逻辑是什么？跟现有的 request 拦截器怎么配合？

你提约束和质疑，它修正方案。 目的是把模糊点全消掉，让后面写代码变成纯执行——AI 不用"想"，照做就行。

第三步：切片执行，逐个跑通
别一口气让它把整个模块写完。先只写最短链路——wx.login → 换 token → 存 storage，跑通了再加用户授权，再加手机号，最后加静默续签。每一轮只干一件事。

聊太久 AI 会"变糊"，上下文有效窗口就那么大。做完一步存下结论，新开一轮带着结论继续，始终让它在最清醒的状态干活。

不同子任务也可以找不同模型——写样式找擅长视觉的，写逻辑找擅长推理的，你做最终整合。

测试阶段要 mock 数据的时候，让 AI 顺手生成个脚本造测试数据就行，这又回到"低上下文"了，秒出的事。

最后一句
AI 不是许愿池，你给方向它才靠谱。 今天回去拿手头正在写的页面，按这三步试一次——区别不在于用不用 AI，在于你怎么喂它。